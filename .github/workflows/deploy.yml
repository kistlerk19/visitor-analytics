name: Deploy LAMP Stack with Disaster Recovery

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  AWS_DEFAULT_REGION: eu-west-1
  TF_ROOT: disaster-recovery

jobs:
  validate:
    name: Validate Terraform
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7
          
      - name: Terraform Format
        run: |
          cd $TF_ROOT
          terraform fmt
          
      - name: Terraform Format Check
        run: |
          cd $TF_ROOT
          terraform fmt -check
          
      - name: Terraform Init
        run: |
          cd $TF_ROOT
          terraform init -backend=false
          
      - name: Terraform Validate
        run: |
          cd $TF_ROOT
          terraform validate

  build:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    needs: validate
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7
          
      - name: Get ECR repository name
        id: get-ecr
        run: |
          cd $TF_ROOT
          cat > terraform.tfvars << EOF
          primary_region = "${{ env.AWS_DEFAULT_REGION }}"
          dr_region = "eu-central-1"
          environment = "prod"
          notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
          aws_account_id = "${{ secrets.AWS_ACCOUNT_ID }}"
          enable_dr = false
          image_tag = "${{ github.sha }}"
          EOF
          aws s3 mb s3://lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }} --region ${{ env.AWS_DEFAULT_REGION }} 2>/dev/null || true
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket = "lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }}"
              key    = "terraform.tfstate"
              region = "${{ env.AWS_DEFAULT_REGION }}"
            }
          }
          EOF
          terraform init
          terraform apply -auto-approve -target=module.primary_ecr
          ECR_REPO_URL=$(terraform output -raw primary_ecr_apache)
          ECR_REPO_NAME=$(echo $ECR_REPO_URL | cut -d'/' -f2)
          echo "ecr_repository_name=$ECR_REPO_NAME" >> $GITHUB_OUTPUT
          echo "ecr_repository_url=$ECR_REPO_URL" >> $GITHUB_OUTPUT
          
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
          
      - name: Build, tag, and push image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ steps.get-ecr.outputs.ecr_repository_name }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -f disaster-recovery/Dockerfile.apache-rds -t $ECR_REPOSITORY .
          docker tag $ECR_REPOSITORY:latest $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

  deploy:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [validate, build]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7
          
      - name: Destroy DR resources
        run: |
          cd $TF_ROOT
          cat > terraform.tfvars << EOF
          primary_region = "${{ env.AWS_DEFAULT_REGION }}"
          dr_region = "eu-central-1"
          environment = "prod"
          notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
          aws_account_id = "${{ secrets.AWS_ACCOUNT_ID }}"
          enable_dr = true
          image_tag = "${{ github.sha }}"
          EOF
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket = "lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }}"
              key    = "terraform.tfstate"
              region = "${{ env.AWS_DEFAULT_REGION }}"
            }
          }
          EOF
          terraform init
          terraform destroy -target=module.dr_networking -target=module.dr_ecs -target=module.dr_security -target=module.dr_ecr -auto-approve 2>/dev/null || true
          
      - name: Clean up unused VPCs
        run: |
          echo "🧹 Cleaning up unused VPCs..."
          aws ec2 describe-vpcs --query 'Vpcs[?IsDefault==`false`].VpcId' --output text | while read vpc_id; do
            if [ -n "$vpc_id" ]; then
              INSTANCES=$(aws ec2 describe-instances --filters "Name=vpc-id,Values=$vpc_id" --query 'Reservations[].Instances[?State.Name!=`terminated`].InstanceId' --output text)
              if [ -z "$INSTANCES" ]; then
                echo "🗑️ Attempting to delete unused VPC: $vpc_id"
                aws ec2 describe-subnets --filters "Name=vpc-id,Values=$vpc_id" --query 'Subnets[].SubnetId' --output text | xargs -r -n1 aws ec2 delete-subnet --subnet-id 2>/dev/null || true
                aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$vpc_id" --query 'InternetGateways[].InternetGatewayId' --output text | while read igw_id; do
                  aws ec2 detach-internet-gateway --internet-gateway-id $igw_id --vpc-id $vpc_id 2>/dev/null || true
                  aws ec2 delete-internet-gateway --internet-gateway-id $igw_id 2>/dev/null || true
                done
                aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$vpc_id" --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' --output text | xargs -r -n1 aws ec2 delete-route-table --route-table-id 2>/dev/null || true
                aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$vpc_id" --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text | xargs -r -n1 aws ec2 delete-security-group --group-id 2>/dev/null || true
                aws ec2 delete-vpc --vpc-id $vpc_id 2>/dev/null || true
              fi
            fi
          done
          
      - name: Clean up existing ECS service
        run: |
          echo "🔍 Checking for existing ECS services..."
          TASK_ARNS=$(aws ecs list-tasks --cluster lamp-visitor-analytics --service-name lamp-visitor-analytics --query 'taskArns[]' --output text 2>/dev/null || echo "")
          if [ -n "$TASK_ARNS" ]; then
            echo "🛑 Stopping all tasks..."
            for task in $TASK_ARNS; do
              aws ecs stop-task --cluster lamp-visitor-analytics --task $task 2>/dev/null || true
            done
          fi
          
          if aws ecs describe-services --cluster lamp-visitor-analytics --services lamp-visitor-analytics 2>/dev/null | grep -q "serviceName"; then
            echo "⏳ Scaling down service to 0..."
            aws ecs update-service --cluster lamp-visitor-analytics --service lamp-visitor-analytics --desired-count 0 2>/dev/null || true
            sleep 30
            echo "🗑️ Force deleting service..."
            aws ecs delete-service --cluster lamp-visitor-analytics --service lamp-visitor-analytics --force 2>/dev/null || true
            
            echo "⏳ Waiting for service deletion..."
            for i in {1..30}; do
              if ! aws ecs describe-services --cluster lamp-visitor-analytics --services lamp-visitor-analytics 2>/dev/null | grep -q "serviceName"; then
                echo "✅ Service deleted successfully"
                break
              fi
              echo "Waiting... ($i/30)"
              sleep 10
            done
          fi
          
          echo "🧹 Cleaning up old task definitions..."
          aws ecs list-task-definitions --family-prefix lamp-visitor-analytics --status ACTIVE --query 'taskDefinitionArns[:-1]' --output text | xargs -r -n1 aws ecs deregister-task-definition --task-definition 2>/dev/null || true
          
      - name: Create terraform.tfvars
        run: |
          cd $TF_ROOT
          cat > terraform.tfvars << EOF
          primary_region = "${{ env.AWS_DEFAULT_REGION }}"
          dr_region = "eu-central-1"
          environment = "prod"
          notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
          aws_account_id = "${{ secrets.AWS_ACCOUNT_ID }}"
          enable_dr = false
          image_tag = "${{ github.sha }}"
          EOF
          
      - name: Create S3 bucket for state
        run: |
          aws s3 mb s3://lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }} --region ${{ env.AWS_DEFAULT_REGION }} 2>/dev/null || true
          aws s3api put-bucket-versioning --bucket lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }} --versioning-configuration Status=Enabled 2>/dev/null || true
          
      - name: Update backend configuration
        run: |
          cd $TF_ROOT
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket = "lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }}"
              key    = "terraform.tfstate"
              region = "${{ env.AWS_DEFAULT_REGION }}"
            }
          }
          EOF
          
      - name: Terraform Init
        run: |
          cd $TF_ROOT
          terraform init
          
      - name: Import existing resources
        run: |
          cd $TF_ROOT
          echo "🔍 Checking for existing resources to import..."
          
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=lamp-visitor-analytics-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
          if [ "$VPC_ID" != "None" ] && [ -n "$VPC_ID" ]; then
            echo "📥 Importing existing VPC: $VPC_ID"
            terraform import module.primary_networking.aws_vpc.main $VPC_ID 2>/dev/null || true
          fi
          
          if aws ecs describe-clusters --clusters lamp-visitor-analytics 2>/dev/null | grep -q "clusterName"; then
            echo "📥 Importing existing ECS cluster"
            terraform import module.primary_ecs.aws_ecs_cluster.main lamp-visitor-analytics 2>/dev/null || true
          fi
          
          ALB_ARN=$(aws elbv2 describe-load-balancers --query 'LoadBalancers[?contains(LoadBalancerName, `alb-`)].LoadBalancerArn | [0]' --output text 2>/dev/null || echo "None")
          if [ "$ALB_ARN" != "None" ] && [ -n "$ALB_ARN" ]; then
            echo "📥 Importing existing ALB: $ALB_ARN"
            terraform import module.primary_ecs.aws_lb.main $ALB_ARN 2>/dev/null || true
          fi
          
          RDS_ID=$(aws rds describe-db-instances --query 'DBInstances[?contains(DBInstanceIdentifier, `lamp-visitor-analytics-db`)].DBInstanceIdentifier | [0]' --output text 2>/dev/null || echo "None")
          if [ "$RDS_ID" != "None" ] && [ -n "$RDS_ID" ]; then
            echo "📥 Importing existing RDS instance: $RDS_ID"
            terraform import module.primary_rds.aws_db_instance.main $RDS_ID 2>/dev/null || true
          fi
          
      - name: Terraform Plan
        run: |
          cd $TF_ROOT
          terraform refresh -auto-approve || true
          terraform plan -out=tfplan -detailed-exitcode || {
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 2 ]; then
              echo "✅ Changes detected, will apply"
            elif [ $EXIT_CODE -eq 1 ]; then
              echo "❌ Plan failed"
              exit 1
            else
              echo "✅ No changes needed"
              touch no-changes
            fi
          }
          
      - name: Terraform Apply
        run: |
          cd $TF_ROOT
          if [ ! -f no-changes ]; then
            echo "🚀 Applying Terraform changes..."
            terraform apply -auto-approve tfplan
          else
            echo "✅ No changes to apply - infrastructure is up to date"
          fi

  test:
    name: Test Deployment
    runs-on: ubuntu-latest
    needs: [validate, deploy]
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}
          
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7
          
      - name: Get ALB DNS
        id: get-alb
        run: |
          cd $TF_ROOT
          cat > backend.tf << EOF
          terraform {
            backend "s3" {
              bucket = "lamp-visitor-analytics-terraform-state-${{ secrets.AWS_ACCOUNT_ID }}"
              key    = "terraform.tfstate"
              region = "${{ env.AWS_DEFAULT_REGION }}"
            }
          }
          EOF
          cat > terraform.tfvars << EOF
          primary_region = "${{ env.AWS_DEFAULT_REGION }}"
          dr_region = "eu-central-1"
          environment = "prod"
          notification_email = "${{ secrets.NOTIFICATION_EMAIL }}"
          aws_account_id = "${{ secrets.AWS_ACCOUNT_ID }}"
          enable_dr = false
          image_tag = "${{ github.sha }}"
          EOF
          terraform init
          ALB_DNS=$(terraform output -raw primary_alb_dns 2>/dev/null || echo "")
          if [ -z "$ALB_DNS" ]; then
            echo "❌ No ALB DNS found in outputs"
            terraform output
            exit 1
          fi
          echo "alb_dns=$ALB_DNS" >> $GITHUB_OUTPUT
          
      - name: Wait for deployment
        run: |
          echo "⏳ Waiting for deployment to stabilize..."
          aws ecs wait services-stable --cluster lamp-visitor-analytics --services lamp-visitor-analytics --cli-read-timeout 600 || {
            echo "Service failed to stabilize, checking status..."
            aws ecs describe-services --cluster lamp-visitor-analytics --services lamp-visitor-analytics
            exit 1
          }
          echo "✅ ECS service is stable"
          
      - name: Health Check Test
        run: |
          echo "🏥 Testing health endpoint..."
          curl -f http://${{ steps.get-alb.outputs.alb_dns }}/health-simple.php || {
            echo "Health check failed"
            exit 1
          }
          
      - name: Main Application Test
        run: |
          echo "🌐 Testing main application..."
          curl -f http://${{ steps.get-alb.outputs.alb_dns }}/ || {
            echo "Main app test failed"
            exit 1
          }
          
      - name: Test Results
        run: echo "🎉 All tests completed successfully"